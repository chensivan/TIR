## What

This paper evaluates whether a state-of-the-art plagirasm detector can tell an assignment solution is generated by human or AI (GPT-J).

## Why

The stunning performance of AI techniques made educators concerned that whether students would use them to cheat on assignments.

## How

They trained a GPT-J model on a set of programming assignments and their solutions. The model can produce solutions given an exercise at different complex level (levell 1 is the simplest, and level 6 is the most advanced). Then the answers are reviewed both by human experts and a SOTA plagirism detector on answer diversity and correctness.

## Findings

This model is capable of fooling the plagiarism detector with a high degree of reliability, and with little human edits the assignments can recevive full marks. Also, the solutions have sufficient diversity to avoid easy detection.

## Ethical and educational implications, and thoughts

Although worrysome, the authors argue that the benefits outweight the risks of their findings. They think that

- Those who is cheating all the way up would likely to fail out or revert to some other form of cheating.
- in-person or live exercises won't be able to use this technique
- instructors can work with this technique, such as using the model to generate a list of solutions and ask students to rank them on different aspects.

Personal note:

- Maneesh also talks about the challenges the society has when dealing with techniques like Deepfake. The fundemental issue is that some people want to lie about something, and no matter how good our tools are at detecting fake thigns or cheating, these people can always come up with ways to tell lies. The other way to help the issue is to educate people with critical thinking on the information they consume (which is less appliable in this paper).

## Where

![office](office.JPG)
